[{"context": "Automatic Locally Robust Estimation with Generated Regressors", "source": "Many economic and causal parameters of interest depend on generated regressors. Examples include structural parameters in models with endogenous variables estimated by control functions and in models with sample selection, treatment effect estimation with propensity score matching, and marginal treatment effects. Inference with generated regressors is complicated by the very complex expression for influence functions and asymptotic variances. To address this problem, we propose Automatic Locally Robust/debiased GMM estimators in a general setting with generated regressors. Importantly, we allow for the generated regressors to be generated from machine learners, such as Random Forest, Neural Nets, Boosting, and many others. We use our results to construct novel Doubly Robust and Locally Robust estimators for the Counterfactual Average Structural Function and Average Partial Effects in models with endogeneity and sample selection, respectively. We provide sufficient conditions for the asymptotic normality of our debiased GMM estimators and investigate their finite sample performance through Monte Carlo simulations.", "target": "", "edits": [], "_id": 2301.10643}, {"context": "Decomposability and Strategy-proofness in Multidimensional Models", "source": "We introduce the notion of a multidimensional hybrid preference domain on a (finite) set of alternatives that is a Cartesian product of finitely many components. We demonstrate that in a model of public goods provision, multidimensional hybrid preferences arise naturally through assembling marginal preferences under the condition of semi-separability - a weakening of separability. The main result shows that under a suitable \"richness\" condition, every strategy-proof rule on this domain can be decomposed into component-wise strategy-proof rules, and more importantly every domain of preferences that reconciles decomposability of rules with strategy-proofness must be a multidimensional hybrid domain.", "target": "", "edits": [], "_id": 2303.10889}, {"context": "Causal inference in network experiments: regression-based analysis and\n  design-based properties", "source": "Investigating interference or spillover effects among units is a central task in many social science problems. Network experiments are powerful tools for this task, which avoids endogeneity by randomly assigning treatments to units over networks. However, it is non-trivial to analyze network experiments properly without imposing strong modeling assumptions. Previously, many researchers have proposed sophisticated point estimators and standard errors for causal effects under network experiments. We further show that regression-based point estimators and standard errors can have strong theoretical guarantees if the regression functions and robust standard errors are carefully specified to accommodate the interference patterns under network experiments. We first recall a well-known result that the Hajek estimator is numerically identical to the coefficient from the weighted-least-squares fit based on the inverse probability of the exposure mapping. Moreover, we demonstrate that the regression-based approach offers three notable advantages: its ease of implementation, the ability to derive standard errors through the same weighted-least-squares fit, and the capacity to integrate covariates into the analysis, thereby enhancing estimation efficiency. Furthermore, we analyze the asymptotic bias of the regression-based network-robust standard errors. Recognizing that the covariance estimator can be anti-conservative, we propose an adjusted covariance estimator to improve the empirical coverage rates. Although we focus on regression-based point estimators and standard errors, our theory holds under the design-based framework, which assumes that the randomness comes solely from the design of network experiments and allows for arbitrary misspecification of the regression models.", "target": "", "edits": [], "_id": 2309.07476}, {"context": "Heterogeneity-robust granular instruments", "source": "Granular instrumental variables (GIV) has experienced sharp growth in empirical macro-finance. The methodology's rise showcases granularity's potential for identification in a wide set of economic environments, like the estimation of spillovers and demand systems. I propose a new estimator--called robust granular instrumental variables (RGIV)--that allows researchers to study unit-level heterogeneity in spillovers within GIV's framework. In contrast to GIV, RGIV also allows for unknown shock variances and does not require skewness of the size distribution of units. I also develop a test of overidentifying restrictions that evaluates RGIV's compatibility with the data, a parameter restriction test that evaluates the appropriateness of the homogeneous spillovers assumption, and extend the framework to allow for observable explanatory variables. Applied to the Euro area, I find strong evidence of country-level heterogeneity in sovereign yield spillovers. In simulations, I show that RGIV produces reliable and informative confidence intervals.", "target": "", "edits": [], "_id": 2304.01273}, {"context": "Structural Advantages for Integrated Builders in MEV-Boost", "source": "Currently, over 90% of Ethereum blocks are built using MEV-Boost, an auction that allows validators to sell their block-building power to builders who compete in an open English auction in each slot. Shortly after the merge, when MEV-Boost was in its infancy, most block builders were neutral, meaning they did not trade themselves but rather aggregated transactions from other traders. Over time, integrated builders, operated by trading firms, began to overtake many of the neutral builders. Outside of the integrated builder teams, little is known about which advantages integration confers beyond latency and how latency advantages distort on-chain trading.   This paper explores these poorly understood advantages. We make two contributions. First, we point out that integrated builders are able to bid truthfully in their own bundle merge and then decide how much profit to take later in the final stages of the PBS auction when more information is available, making the auction for them look closer to a second-price auction while independent searchers are stuck in a first-price auction. Second, we find that latency disadvantages convey a winner's curse on slow bidders when underlying values depend on a stochastic price process that change as bids are submitted.", "target": "", "edits": [], "_id": 2311.09083}, {"context": "Belief identification by proxy", "source": "It is well known that individual beliefs cannot be identified using traditional choice data, unless we exogenously assume state-independent utilities. In this paper, I propose a novel methodology that solves this long-standing identification problem in a simple way. This method relies on the extending the state space by introducing a proxy, for which the agent has no stakes conditional on the original state space. The latter allows us to identify the agent's conditional beliefs about the proxy given each state realization, which in turn suffices for indirectly identifying her beliefs about the original state space. This approach is analogous to the one of instrumental variables in econometrics. Similarly to instrumental variables, the appeal of this method comes from the flexibility in selecting a proxy.", "target": "", "edits": [], "_id": 2311.13394}, {"context": "The Bounds of Mediated Communication", "source": "We study the bounds of mediated communication in sender-receiver games in which the sender's payoff is state-independent. We show that the feasible distributions over the receiver's beliefs under mediation are those that induce zero correlation, but not necessarily independence, between the sender's payoff and the receiver's belief. Mediation attains the upper bound on the sender's value, i.e., the Bayesian persuasion value, if and only if this value is attainable under unmediated communication, i.e., cheap talk. The lower bound is given by the cheap talk payoff. We provide a geometric characterization of when mediation strictly improves on this using the quasiconcave and quasiconvex envelopes of the sender's value function. In canonical environments, mediation is strictly valuable when the sender has countervailing incentives in the space of the receiver's belief. We apply our results to asymmetric-information settings such as bilateral trade and lobbying and explicitly construct mediation policies that increase the surplus of the informed and uninformed parties with respect to unmediated communication.", "target": "", "edits": [], "_id": 2303.06244}, {"context": "Fatal errors and misuse of mathematics in the Hong-Page Theorem and\n  Landemore's epistemic argument", "source": "In the pursuit of understanding collective intelligence, the Hong-Page Theorems have been presented as cornerstones of the interplay between diversity and ability. However, upon rigorous examination, there seem to be inherent flaws and misinterpretations within these theorems. H\\'el\\`ene Landemore's application of these theorems in her epistemic argument and her political proposal showcases a rather unsettling misuse of mathematical principles. This paper critically dissects the HongPage Theorems, revealing significant inconsistencies and oversights, and underscores the indispensable role of 'ability' in group problem-solving contexts. This paper aims not to undermine the importance of diversity, but rather to highlight the dangers of misusing mathematical principles and the necessity for a more nuanced comprehension of mathematical results when applying them to social sciences.", "target": "", "edits": [], "_id": 2307.04709}, {"context": "Considering Risk Aversion in Economic Evaluation: A Rank Dependent\n  Approach", "source": "This paper presents a method for incorporating risk aversion into existing decision tree models used in economic evaluations. The method involves applying a probability weighting function based on rank dependent utility theory to reduced lotteries in the decision tree model. This adaptation embodies the fact that different decision makers can observe the same decision tree model structure but come to different conclusions about the optimal treatment. The proposed solution to this problem is to compensate risk-averse decision makers to use the efficient technology that they are reluctant to adopt.", "target": "", "edits": [], "_id": 2311.07905}, {"context": "Test-Optional Admissions", "source": "The Covid-19 pandemic has accelerated the trend of many colleges moving to test-optional, and in some cases test-blind, admissions policies. A frequent claim is that by not seeing standardized test scores, a college is able to admit a student body that it prefers, such as one with more diversity. But how can observing less information allow a college to improve its decisions? We argue that test-optional policies may be driven by social pressure on colleges' admission decisions. We propose a model of college admissions in which a college disagrees with society on which students should be admitted. We show how the college can use a test-optional policy to reduce its \"disagreement cost\" with society, regardless of whether this results in a preferred student pool. We discuss which students either benefit from or are harmed by a test-optional policy. In an application, we study how a ban on using race in admissions may result in more colleges going test optional or test blind.", "target": "", "edits": [], "_id": 2304.07551}, {"context": "The learning effects of subsidies to bundled goods: a semiparametric\n  approach", "source": "Can temporary subsidies to bundles induce long-run changes in demand due to learning about the relative quality of one of its constituent goods? This paper provides theoretical and experimental evidence on the role of this mechanism. Theoretically, we introduce a model where an agent learns about the quality of an innovation on an essential good through consumption. Our results show that the contemporaneous effect of a one-off subsidy to a bundle that contains the innovation may be decomposed into a direct price effect, and an indirect learning motive, whereby an agent leverages the discount to increase the informational bequest left to her future selves. We then assess the predictions of our theory in a randomised experiment in a ridesharing platform. The experiment provided two-week discounts for car trips integrating with a train or metro station (a bundle). Given the heavy-tailed nature of our data, we follow \\cite{Athey2023} and, motivated by our theory, propose a semiparametric model for treatment effects that enables the construction of more efficient estimators. We introduce a statistically efficient estimator for our model by relying on L-moments, a robust alternative to standard moments. Our estimator immediately yields a specification test for the semiparametric model; moreover, in our adopted parametrisation, it can be easily computed through generalized least squares. Our empirical results indicate that a two-week 50\\% discount on car trips integrating with train/metro leads to a contemporaneous increase in the demand for integrated rides, and, consistent with our learning model, persistent changes in the mean and dispersion of nonintegrated rides. These effects persist for over four months after the discount. A simple calibration of our model shows that around 40\\% to 50\\% of the estimated contemporaneous increase in integrated rides may be attributed to a learning motive.", "target": "", "edits": [], "_id": 2311.01217}, {"context": "Optimal Estimation Methodologies for Panel Data Regression Models", "source": "This survey study discusses main aspects to optimal estimation methodologies for panel data regression models. In particular, we present current methodological developments for modeling stationary panel data as well as robust methods for estimation and inference in nonstationary panel data regression models. Some applications from the network econometrics and high dimensional statistics literature are also discussed within a stationary time series environment.", "target": "", "edits": [], "_id": 2311.03471}, {"context": "Does regional variation in wage levels identify the effects of a\n  national minimum wage?", "source": "This paper examines the identification assumptions underlying two types of estimators of the causal effects of minimum wages based on regional variation in wage levels: the \"effective minimum wage\" and the \"fraction affected/gap\" designs. For the effective minimum wage design, I show that the identification assumptions emphasized by Lee (1999) are crucial for unbiased estimation but difficult to satisfy in empirical applications for reasons arising from economic theory. For the fraction affected design at the region level, I show that economic factors such as a common trend in the dispersion of worker productivity or regional convergence in GDP per capita may lead to violations of the \"parallel trends\" identifying assumption. The paper suggests ways to increase the likelihood of detecting those issues when implementing checks for parallel pre-trends. I also show that this design may be subject to biases arising from the misspecification of the treatment intensity variable, especially when the minimum wage strongly affects employment and wages.", "target": "", "edits": [], "_id": 2307.01284}, {"context": "Finite Sample Performance of a Conduct Parameter Test in Homogenous\n  Goods Markets", "source": "We assess the finite sample performance of the conduct parameter test in homogeneous goods markets. Statistical power rises with an increase in the number of markets, a larger conduct parameter, and a stronger demand rotation instrument. However, even with a moderate number of markets and five firms, regardless of instrument strength and the utilization of optimal instruments, rejecting the null hypothesis of perfect competition remains challenging. Our findings indicate that empirical results that fail to reject perfect competition are a consequence of the limited number of markets rather than methodological deficiencies.", "target": "", "edits": [], "_id": 2310.04576}, {"context": "Patience ensures fairness", "source": "We revisit the problem of fairly allocating a sequence of time slots when agents may have different levels of patience (Mackenzie and Komornik, 2023). For each number of agents, we provide a lower threshold and an upper threshold on the level of patience such that (i) if each agent is at least as patient as the lower threshold, then there is a proportional allocation, and (ii) if each agent is at least as patient as the upper threshold and moreover has weak preference for earlier time slots, then there is an envy-free allocation. In both cases, the proof is constructive.", "target": "", "edits": [], "_id": 2311.06092}, {"context": "Locally Asymptotically Minimax Statistical Treatment Rules Under Partial\n  Identification", "source": "Policymakers often desire a statistical treatment rule (STR) that determines a treatment assignment rule deployed in a future population from available data. With the true knowledge of the data generating process, the average treatment effect (ATE) is the key quantity characterizing the optimal treatment rule. Unfortunately, the ATE is often not point identified but partially identified. Presuming the partial identification of the ATE, this study conducts a local asymptotic analysis and develops the locally asymptotically minimax (LAM) STR. The analysis does not assume the full differentiability but the directional differentiability of the boundary functions of the identification region of the ATE. Accordingly, the study shows that the LAM STR differs from the plug-in STR. A simulation study also demonstrates that the LAM STR outperforms the plug-in STR.", "target": "", "edits": [], "_id": 2311.08958}, {"context": "Stable partitions for proportional generalized claims problems", "source": "We consider a set of agents who have claims on an endowment that is not large enough to cover all claims. Agents can form coalitions but a minimal coalition size $\\theta$ is required to have positive coalitional funding that is proportional to the sum of the claims of its members. We analyze the structure of stable partitions when coalition members use well-behaved rules to allocate coalitional endowments, e.g., the well-known constrained equal awards rule (CEA) or the constrained equal losses rule (CEL).For continuous, (strictly) resource monotonic, and consistent rules, stable partitions with (mostly) $\\theta$-size coalitions emerge. For CEA and CEL we provide algorithms to construct such a stable partition formed by $\\theta$-size coalitions.", "target": "", "edits": [], "_id": 2311.0395}, {"context": "Posterior-Mean Separable Costs of Information Acquisition", "source": "We analyze a problem of revealed preference given state-dependent stochastic choice data in which the payoff to a decision maker (DM) only depends on their beliefs about posterior means. Often, the DM must also learn about or pay attention to the state; in applied work on this subject, a convenient assumption is that the costs of such learning are linearly dependent in the distribution over posterior means. We provide testable conditions to identify whether this assumption holds. This allows for the use of information design techniques to solve the DM's problem.", "target": "", "edits": [], "_id": 2311.09496}, {"context": "The Complexity of Corporate Culture as a Potential Source of Firm Profit\n  Differentials", "source": "This paper proposes an addition to the firm-based perspective on intra-industry profitability differentials by modelling a business organisation as a complex adaptive system. The presented agent-based model introduces an endogenous similarity-based social network and employees' reactions to dynamic management strategies informed by key company benchmarks. The value-based decision-making of employees shapes the behaviour of others through their perception of social norms from which a corporate culture emerges. These elements induce intertwined feedback mechanisms which lead to unforeseen profitability outcomes. The simulations reveal that variants of extreme adaptation of management style yield higher profitability in the long run than the more moderate alternatives. Furthermore, we observe convergence towards a dominant management strategy with low intensity in monitoring efforts as well as high monetary incentivisation of cooperative behaviour. The results suggest that measures increasing the connectedness of the workforce across all four value groups might be advisable to escape potential lock-in situation and thus raise profitability. A further positive impact on profitability can be achieved through knowledge about the distribution of personal values among a firm's employees. Choosing appropriate and enabling management strategies, and sticking to them in the long run, can support the realisation of the inherent self-organisational capacities of the workforce, ultimately leading to higher profitability through cultural stability.", "target": "", "edits": [], "_id": 2305.14029}, {"context": "Pooled Bewley Estimator of Long Run Relationships in Dynamic\n  Heterogenous Panels", "source": "Using a transformation of the autoregressive distributed lag model due to Bewley, a novel pooled Bewley (PB) estimator of long-run coefficients for dynamic panels with heterogeneous short-run dynamics is proposed. The PB estimator is directly comparable to the widely used Pooled Mean Group (PMG) estimator, and is shown to be consistent and asymptotically normal. Monte Carlo simulations show good small sample performance of PB compared to the existing estimators in the literature, namely PMG, panel dynamic OLS (PDOLS), and panel fully-modified OLS (FMOLS). Application of two bias-correction methods and a bootstrapping of critical values to conduct inference robust to cross-sectional dependence of errors are also considered. The utility of the PB estimator is illustrated in an empirical application to the aggregate consumption function.", "target": "", "edits": [], "_id": 2311.02196}, {"_thresh_template": "# As fine-grained annotation requires complex categories, many successful fine-grained \n# typologies organize their classification in trees. Our interface is unique in that it can \n# render any arbitrary annotation tree, no matter its depth or breath. We will begin with \n# simple annotation setups, and then showcase some complex examples.\n\n# Click the Instructions button to view this :)\n\ninstructions: |\n  ## Adding instructions to your interface\n  Instructions are formatted with [Markdown](https://www.markdownguide.org/cheat-sheet/). \n  You can use the `prepend_instructions` argument to display this text above the interface, or have an \"Instructions\" button.\n\n  ### Formatting\n  Markdown allows creating **bold** or *italicized* text and:\n  - lists\n  - of\n  - items\n\n  ```\n  You can even add blocks of code\n  ```\n  ---\n\n# Comment this to package the instructions using an \"Instructions\" button\n# prepend_instructions: true\n\n# ========================================================================================\n# ========================================================================================\n\n\nedits:\n  # You can specify any number of individual questions\n  - name: multi_question\n    label: \"Annotate Term\"\n    enable_input: true\n    color: blue\n    icon: fa-pen\n    type: single_span\n    annotation:\n      - name: defn_question\n        label: \"Definition\"\n        question: \"Write a one-sentence definition of this term. If you wish to use Google, please use the following search format `define:\\\"<term>\\\"`, substituting your identified term for `<term>` (make sure to include the quotation marks).\"\n        options: textarea\n      - name: difficulty_question\n        label: \"Difficulty\"\n        question: \"How difficult is defining this term?\"\n        options: likert-3\n      - name: category_question\n        label: \"Category\"\n        question: \"Which category would you this term to?\"\n        options: \n          - name: a1\n            label: \"Concept/phrase\"\n          - name: a2\n            label: \"Abbreviation\"\n          - name: a3\n            label: \"Named Entity\"\n          # - name: child_4\n          #   label: \"Other\"\n      - name: multisense_question\n        label: \"Multisense\"\n        question: \"Does this term have different meanings in other domain contexts? If you're uncertain, choose 'Unsure'.\"\n        options: \n          - name: b1\n            label: \"Yes\"\n          - name: b2\n            label: \"No\"\n          - name: b3\n            label: \"Unsure\"\n\n\n\n# ========================================================================================\n# ========================================================================================\n\ntemplate_name: llm_dfs\ntemplate_label: Scientific Concept Identification & Definition\ntemplate_description: TODO\n\n\ndisplay:\n - side-by-side         # shows text and editor next to each other\n#  - text-side-by-side    # shows source and target next to each other\n#  - disable-lines        # disables lines between annotations which can be distracting\n#  - hide-context         # hides the context by default, adding a \"show context\" button\n\ndisable:\n- download        # Disables data download, useful for crowdsourcing\n# - upload          # Disables data upload, useful if data is provided with ?d= parameter\n# - selection     # Disables edit selection\n# - annotation      # Disables edit annotation"}]