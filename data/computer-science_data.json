[{"context": "FPO++: Efficient Encoding and Rendering of Dynamic Neural Radiance\n  Fields by Analyzing and Enhancing Fourier PlenOctrees", "source": "Fourier PlenOctrees have shown to be an efficient representation for real-time rendering of dynamic Neural Radiance Fields (NeRF). Despite its many advantages, this method suffers from artifacts introduced by the involved compression when combining it with recent state-of-the-art techniques for training the static per-frame NeRF models. In this paper, we perform an in-depth analysis of these artifacts and leverage the resulting insights to propose an improved representation. In particular, we present a novel density encoding that adapts the Fourier-based compression to the characteristics of the transfer function used by the underlying volume rendering procedure and leads to a substantial reduction of artifacts in the dynamic model. Furthermore, we show an augmentation of the training data that relaxes the periodicity assumption of the compression. We demonstrate the effectiveness of our enhanced Fourier PlenOctrees in the scope of quantitative and qualitative evaluations on synthetic and real-world scenes.", "target": "", "edits": [], "_id": 2310.2071}, {"context": "Data-Centric Long-Tailed Image Recognition", "source": "In the context of the long-tail scenario, models exhibit a strong demand for high-quality data. Data-centric approaches aim to enhance both the quantity and quality of data to improve model performance. Among these approaches, information augmentation has been progressively introduced as a crucial category. It achieves a balance in model performance by augmenting the richness and quantity of samples in the tail classes. However, there is currently a lack of research into the underlying mechanisms explaining the effectiveness of information augmentation methods. Consequently, the utilization of information augmentation in long-tail recognition tasks relies heavily on empirical and intricate fine-tuning. This work makes two primary contributions. Firstly, we approach the problem from the perspectives of feature diversity and distribution shift, introducing the concept of Feature Diversity Gain (FDG) to elucidate why information augmentation is effective. We find that the performance of information augmentation can be explained by FDG, and its performance peaks when FDG achieves an appropriate balance. Experimental results demonstrate that by using FDG to select augmented data, we can further enhance model performance without the need for any modifications to the model's architecture. Thus, data-centric approaches hold significant potential in the field of long-tail recognition, beyond the development of new model structures. Furthermore, we systematically introduce the core components and fundamental tasks of a data-centric long-tail learning framework for the first time. These core components guide the implementation and deployment of the system, while the corresponding fundamental tasks refine and expand the research area.", "target": "", "edits": [], "_id": 2311.01744}, {"context": "Memristor-based hardware and algorithms for higher-order Hopfield\n  optimization solver outperforming quadratic Ising machines", "source": "Ising solvers offer a promising physics-based approach to tackle the challenging class of combinatorial optimization problems. However, typical solvers operate in a quadratic energy space, having only pair-wise coupling elements which already dominate area and energy. We show that such quadratization can cause severe problems: increased dimensionality, a rugged search landscape, and misalignment with the original objective function. Here, we design and quantify a higher-order Hopfield optimization solver, with 28nm CMOS technology and memristive couplings for lower area and energy computations. We combine algorithmic and circuit analysis to show quantitative advantages over quadratic Ising Machines (IM)s, yielding 48x and 72x reduction in time-to-solution (TTS) and energy-to-solution (ETS) respectively for Boolean satisfiability problems of 150 variables, with favorable scaling.", "target": "", "edits": [], "_id": 2311.01171}, {"context": "A Step Closer to Comprehensive Answers: Constrained Multi-Stage Question\n  Decomposition with Large Language Models", "source": "While large language models exhibit remarkable performance in the Question Answering task, they are susceptible to hallucinations. Challenges arise when these models grapple with understanding multi-hop relations in complex questions or lack the necessary knowledge for a comprehensive response. To address this issue, we introduce the \"Decompose-and-Query\" framework (D&Q). This framework guides the model to think and utilize external knowledge similar to ReAct, while also restricting its thinking to reliable information, effectively mitigating the risk of hallucinations. Experiments confirm the effectiveness of D&Q: On our ChitChatQA dataset, D&Q does not lose to ChatGPT in 67% of cases; on the HotPotQA question-only setting, D&Q achieved an F1 score of 59.6%. Our code is available at https://github.com/alkaidpku/DQ-ToolQA.", "target": "", "edits": [], "_id": 2311.07491}, {"context": "Learn to Refuse: Making Large Language Models More Controllable and\n  Reliable through Knowledge Scope Limitation and Refusal Mechanism", "source": "Large language models (LLMs) have demonstrated impressive language understanding and generation capabilities, enabling them to answer a wide range of questions across various domains. However, these models are not flawless and often produce responses that contain errors or misinformation. These inaccuracies, commonly referred to as hallucinations, render LLMs unreliable and even unusable in many scenarios. In this paper, our focus is on mitigating the issue of hallucination in LLMs, particularly in the context of question-answering. Instead of attempting to answer all questions, we explore a refusal mechanism that instructs LLMs to refuse to answer challenging questions in order to avoid errors. We then propose a simple yet effective solution called Learn to Refuse (L2R), which incorporates the refusal mechanism to enable LLMs to recognize and refuse to answer questions that they find difficult to address. To achieve this, we utilize a structured knowledge base to represent all the LLM's understanding of the world, enabling it to provide traceable gold knowledge. This knowledge base is separate from the LLM and initially empty, and it is progressively expanded with validated knowledge. When an LLM encounters questions outside its domain, the system recognizes its knowledge scope and determines whether it can answer the question independently. Additionally, we introduce a method for automatically and efficiently expanding the knowledge base of LLMs. Through qualitative and quantitative analysis, we demonstrate that our approach enhances the controllability and reliability of LLMs.", "target": "", "edits": [], "_id": 2311.01041}, {"context": "Analysis of NaN Divergence in Training Monocular Depth Estimation Model", "source": "The latest advances in deep learning have facilitated the development of highly accurate monocular depth estimation models. However, when training a monocular depth estimation network, practitioners and researchers have observed not a number (NaN) loss, which disrupts gradient descent optimization. Although several practitioners have reported the stochastic and mysterious occurrence of NaN loss that bothers training, its root cause is not discussed in the literature. This study conducted an in-depth analysis of NaN loss during training a monocular depth estimation network and identified three types of vulnerabilities that cause NaN loss: 1) the use of square root loss, which leads to an unstable gradient; 2) the log-sigmoid function, which exhibits numerical stability issues; and 3) certain variance implementations, which yield incorrect computations. Furthermore, for each vulnerability, the occurrence of NaN loss was demonstrated and practical guidelines to prevent NaN loss were presented. Experiments showed that both optimization stability and performance on monocular depth estimation could be improved by following our guidelines.", "target": "", "edits": [], "_id": 2311.03938}, {"context": "Boon: A Neural Search Engine for Cross-Modal Information Retrieval", "source": "Visual-Semantic Embedding (VSE) networks can help search engines better understand the meaning behind visual content and associate it with relevant textual information, leading to more accurate search results. VSE networks can be used in cross-modal search engines to embed image and textual descriptions in a shared space, enabling image-to-text and text-to-image retrieval tasks. However, the full potential of VSE networks for search engines has yet to be fully explored. This paper presents Boon, a novel cross-modal search engine that combines two state-of-the-art networks: the GPT-3.5-turbo large language model, and the VSE network VITR (VIsion Transformers with Relation-focused learning) to enhance the engine's capabilities in extracting and reasoning with regional relationships in images. VITR employs encoders from CLIP that were trained with 400 million image-description pairs and it was fine-turned on the RefCOCOg dataset. Boon's neural-based components serve as its main functionalities: 1) a 'cross-modal search engine' that enables end-users to perform image-to-text and text-to-image retrieval. 2) a 'multi-lingual conversational AI' component that enables the end-user to converse about one or more images selected by the end-user. Such a feature makes the search engine accessible to a wide audience, including those with visual impairments. 3) Boon is multi-lingual and can take queries and handle conversations about images in multiple languages. Boon was implemented using the Django and PyTorch frameworks. The interface and capabilities of the Boon search engine are demonstrated using the RefCOCOg dataset, and the engine's ability to search for multimedia through the web is facilitated by Google's API.", "target": "", "edits": [], "_id": 2307.1424}, {"context": "Perspectives on Large Language Models for Relevance Judgment", "source": "When asked, large language models (LLMs) like ChatGPT claim that they can assist with relevance judgments but it is not clear whether automated judgments can reliably be used in evaluations of retrieval systems. In this perspectives paper, we discuss possible ways for LLMs to support relevance judgments along with concerns and issues that arise. We devise a human--machine collaboration spectrum that allows to categorize different relevance judgment strategies, based on how much humans rely on machines. For the extreme point of \"fully automated judgments\", we further include a pilot experiment on whether LLM-based relevance judgments correlate with judgments from trained human assessors. We conclude the paper by providing opposing perspectives for and against the use of~LLMs for automatic relevance judgments, and a compromise perspective, informed by our analyses of the literature, our preliminary experimental evidence, and our experience as IR researchers.", "target": "", "edits": [], "_id": 2304.09161}, {"context": "Optimal Fidelity Selection for Improved Performance in Human-in-the-Loop\n  Queues for Underwater Search", "source": "In the context of human-supervised autonomy, we study the problem of optimal fidelity selection for a human operator performing an underwater visual search task. Human performance depends on various cognitive factors such as workload and fatigue. We perform human experiments in which participants perform two tasks simultaneously: a primary task, which is subject to evaluation, and a secondary task to estimate their workload. The primary task requires participants to search for underwater mines in videos, while the secondary task involves a simple visual test where they respond when a green light displayed on the side of their screens turns red. Videos arrive as a Poisson process and are stacked in a queue to be serviced by the human operator. The operator can choose to watch the video with either normal or high fidelity, with normal fidelity videos playing at three times the speed of high fidelity ones. Participants receive rewards for their accuracy in mine detection for each primary task and penalties based on the number of videos waiting in the queue. We consider the workload of the operator as a hidden state and model the workload dynamics as an Input-Output Hidden Markov Model (IOHMM). We use a Partially Observable Markov Decision Process (POMDP) to learn an optimal fidelity selection policy, where the objective is to maximize total rewards. Our results demonstrate improved performance when videos are serviced based on the optimal fidelity policy compared to a baseline where humans choose the fidelity level themselves.", "target": "", "edits": [], "_id": 2311.06381}, {"context": "Parity Games on Temporal Graphs", "source": "Temporal graphs are a popular modelling mechanism for dynamic complex systems that extend ordinary graphs with discrete time. Simply put, time progresses one unit per step and the availability of edges can change with time. We consider the complexity of solving $\\omega$-regular games played on temporal graphs where the edge availability is ultimately periodic and fixed a priori.   We show that solving parity games on temporal graphs is decidable in PSPACE, only assuming the edge predicate itself is in PSPACE. A matching lower bound already holds for what we call punctual reachability games on static graphs, where one player wants to reach the target at a given, binary encoded, point in time. We further study syntactic restrictions that imply more efficient procedures. In particular, if the edge predicate is in $P$ and is monotonically increasing for one player and decreasing for the other, then the complexity of solving games is only polynomially increased compared to static graphs.", "target": "", "edits": [], "_id": 2310.12701}, {"context": "A Comprehensive Overview of Large Language Models", "source": "Large Language Models (LLMs) have recently demonstrated remarkable capabilities in natural language processing tasks and beyond. This success of LLMs has led to a large influx of research contributions in this direction. These works encompass diverse topics such as architectural innovations of the underlying neural networks, context length improvements, model alignment, training datasets, benchmarking, efficiency and more. With the rapid development of techniques and regular breakthroughs in LLM research, it has become considerably challenging to perceive the bigger picture of the advances in this direction. Considering the rapidly emerging plethora of literature on LLMs, it is imperative that the research community is able to benefit from a concise yet comprehensive overview of the recent developments in this field. This article provides that overview to the research community. It not only focuses on a systematic treatment of the existing literature on a broad range of LLM related concept, but also pays special attention to providing comprehensive summaries with extensive details about the individual existing models, datasets and major insights. We also pay heed to aligning our overview with the emerging outlook of this research direction by accounting for the other recently materializing reviews of the broader research direction of LLMs. Our self-contained comprehensive overview of LLMs discusses relevant background concepts along with covering the advanced topics at the frontier of this research direction. This review article is intended to not only provide a systematic survey, but also a quick comprehensive reference for the researchers and practitioners to draw insights from extensive informative summaries of the existing works to advance the LLM research direction.", "target": "", "edits": [], "_id": 2307.06435}, {"context": "Image Transformation for IoT Time-Series Data: A Review", "source": "In the era of the Internet of Things (IoT), where smartphones, built-in systems, wireless sensors, and nearly every smart device connect through local networks or the internet, billions of smart things communicate with each other and generate vast amounts of time-series data. As IoT time-series data is high-dimensional and high-frequency, time-series classification or regression has been a challenging issue in IoT. Recently, deep learning algorithms have demonstrated superior performance results in time-series data classification in many smart and intelligent IoT applications. However, it is hard to explore the hidden dynamic patterns and trends in time-series. Recent studies show that transforming IoT data into images improves the performance of the learning model. In this paper, we present a review of these studies which use image transformation/encoding techniques in IoT domain. We examine the studies according to their encoding techniques, data types, and application areas. Lastly, we emphasize the challenges and future dimensions of image transformation.", "target": "", "edits": [], "_id": 2311.12742}, {"context": "MARRS: Multimodal Reference Resolution System", "source": "Successfully handling context is essential for any dialog understanding task. This context maybe be conversational (relying on previous user queries or system responses), visual (relying on what the user sees, for example, on their screen), or background (based on signals such as a ringing alarm or playing music). In this work, we present an overview of MARRS, or Multimodal Reference Resolution System, an on-device framework within a Natural Language Understanding system, responsible for handling conversational, visual and background context. In particular, we present different machine learning models to enable handing contextual queries; specifically, one to enable reference resolution, and one to handle context via query rewriting. We also describe how these models complement each other to form a unified, coherent, lightweight system that can understand context while preserving user privacy.", "target": "", "edits": [], "_id": 2311.0165}, {"context": "Sponsorship Disclosure in Native Advertising: A Theoretical Framework", "source": "Native advertising is one of the fastest growing areas of online promotion. After reviewing extant literature via EBSCOhost database, this study draws on Persuasion Knowledge Model and develops a theoretical framework which facilitates a clearer understanding of the relationship between sponsorship disclosure in native advertising and consumer outcome. The framework suggests that sponsorship disclosure has a negative effect on electronic word of mouth (eWOM), and further proposes the interplay between the main effect with brand prominence and the type of device. This is highly relevant to marketer as regulators have been pressuring for the disclosure of native advertising. As this is likely to have detrimental effect to the eWOM, marketer may employ the boundary conditions proposed by this framework to attenuate that negative effect.", "target": "", "edits": [], "_id": 2311.01051}, {"context": "Community-Aware Efficient Graph Contrastive Learning via Personalized\n  Self-Training", "source": "In recent years, graph contrastive learning (GCL) has emerged as one of the optimal solutions for various supervised tasks at the node level. However, for unsupervised and structure-related tasks such as community detection, current GCL algorithms face difficulties in acquiring the necessary community-level information, resulting in poor performance. In addition, general contrastive learning algorithms improve the performance of downstream tasks by increasing the number of negative samples, which leads to severe class collision and unfairness of community detection. To address above issues, we propose a novel Community-aware Efficient Graph Contrastive Learning Framework (CEGCL) to jointly learn community partition and node representations in an end-to-end manner. Specifically, we first design a personalized self-training (PeST) strategy for unsupervised scenarios, which enables our model to capture precise community-level personalized information in a graph. With the benefit of the PeST, we alleviate class collision and unfairness without sacrificing the overall model performance. Furthermore, the aligned graph clustering (AlGC) is employed to obtain the community partition. In this module, we align the clustering space of our downstream task with that in PeST to achieve more consistent node embeddings. Finally, we demonstrate the effectiveness of our model for community detection both theoretically and experimentally. Extensive experimental results also show that our CEGCL exhibits state-of-the-art performance on three benchmark datasets with different scales.", "target": "", "edits": [], "_id": 2311.11073}, {"context": "FVP: Fourier Visual Prompting for Source-Free Unsupervised Domain\n  Adaptation of Medical Image Segmentation", "source": "Medical image segmentation methods normally perform poorly when there is a domain shift between training and testing data. Unsupervised Domain Adaptation (UDA) addresses the domain shift problem by training the model using both labeled data from the source domain and unlabeled data from the target domain. Source-Free UDA (SFUDA) was recently proposed for UDA without requiring the source data during the adaptation, due to data privacy or data transmission issues, which normally adapts the pre-trained deep model in the testing stage. However, in real clinical scenarios of medical image segmentation, the trained model is normally frozen in the testing stage. In this paper, we propose Fourier Visual Prompting (FVP) for SFUDA of medical image segmentation. Inspired by prompting learning in natural language processing, FVP steers the frozen pre-trained model to perform well in the target domain by adding a visual prompt to the input target data. In FVP, the visual prompt is parameterized using only a small amount of low-frequency learnable parameters in the input frequency space, and is learned by minimizing the segmentation loss between the predicted segmentation of the prompted target image and reliable pseudo segmentation label of the target image under the frozen model. To our knowledge, FVP is the first work to apply visual prompts to SFUDA for medical image segmentation. The proposed FVP is validated using three public datasets, and experiments demonstrate that FVP yields better segmentation results, compared with various existing methods.", "target": "", "edits": [], "_id": 2304.13672}, {"context": "BoIR: Box-Supervised Instance Representation for Multi-Person Pose\n  Estimation", "source": "Single-stage multi-person human pose estimation (MPPE) methods have shown great performance improvements, but existing methods fail to disentangle features by individual instances under crowded scenes. In this paper, we propose a bounding box-level instance representation learning called BoIR, which simultaneously solves instance detection, instance disentanglement, and instance-keypoint association problems. Our new instance embedding loss provides a learning signal on the entire area of the image with bounding box annotations, achieving globally consistent and disentangled instance representation. Our method exploits multi-task learning of bottom-up keypoint estimation, bounding box regression, and contrastive instance embedding learning, without additional computational cost during inference. BoIR is effective for crowded scenes, outperforming state-of-the-art on COCO val (0.8 AP), COCO test-dev (0.5 AP), CrowdPose (4.9 AP), and OCHuman (3.5 AP). Code will be available at https://github.com/uyoung-jeong/BoIR", "target": "", "edits": [], "_id": 2309.14072}, {"context": "DEMASQ: Unmasking the ChatGPT Wordsmith", "source": "The potential misuse of ChatGPT and other Large Language Models (LLMs) has raised concerns regarding the dissemination of false information, plagiarism, academic dishonesty, and fraudulent activities. Consequently, distinguishing between AI-generated and human-generated content has emerged as an intriguing research topic. However, current text detection methods lack precision and are often restricted to specific tasks or domains, making them inadequate for identifying content generated by ChatGPT. In this paper, we propose an effective ChatGPT detector named DEMASQ, which accurately identifies ChatGPT-generated content. Our method addresses two critical factors: (i) the distinct biases in text composition observed in human- and machine-generated content and (ii) the alterations made by humans to evade previous detection methods. DEMASQ is an energy-based detection model that incorporates novel aspects, such as (i) optimization inspired by the Doppler effect to capture the interdependence between input text embeddings and output labels, and (ii) the use of explainable AI techniques to generate diverse perturbations. To evaluate our detector, we create a benchmark dataset comprising a mixture of prompts from both ChatGPT and humans, encompassing domains such as medical, open Q&A, finance, wiki, and Reddit. Our evaluation demonstrates that DEMASQ achieves high accuracy in identifying content generated by ChatGPT.", "target": "", "edits": [], "_id": 2311.05019}, {"context": "Improving Cardiovascular Disease Prediction Through Comparative Analysis\n  of Machine Learning Models: A Case Study on Myocardial Infarction", "source": "Cardiovascular disease remains a leading cause of mortality in the contemporary world. Its association with smoking, elevated blood pressure, and cholesterol levels underscores the significance of these risk factors. This study addresses the challenge of predicting myocardial illness, a formidable task in medical research. Accurate predictions are pivotal for refining healthcare strategies. This investigation conducts a comparative analysis of six distinct machine learning models: Logistic Regression, Support Vector Machine, Decision Tree, Bagging, XGBoost, and LightGBM. The attained outcomes exhibit promise, with accuracy rates as follows: Logistic Regression (81.00%), Support Vector Machine (75.01%), XGBoost (92.72%), LightGBM (90.60%), Decision Tree (82.30%), and Bagging (83.01%). Notably, XGBoost emerges as the top-performing model. These findings underscore its potential to enhance predictive precision for coronary infarction. As the prevalence of cardiovascular risk factors persists, incorporating advanced machine learning techniques holds the potential to refine proactive medical interventions.", "target": "", "edits": [], "_id": 2311.00517}, {"context": "Overcoming membrane locking in quadratic NURBS-based discretizations of\n  linear Kirchhoff-Love shells: CAS elements", "source": "Quadratic NURBS-based discretizations of the Galerkin method suffer from membrane locking when applied to Kirchhoff-Love shell formulations. Membrane locking causes not only smaller displacements than expected, but also large-amplitude spurious oscillations of the membrane forces. Continuous-assumed-strain (CAS) elements have been recently introduced to remove membrane locking in quadratic NURBS-based discretizations of linear plane curved Kirchhoff rods (Casquero et al., CMAME, 2022). In this work, we generalize CAS elements to vanquish membrane locking in quadratic NURBS-based discretizations of linear Kirchhoff-Love shells. CAS elements bilinearly interpolate the membrane strains at the four corners of each element. Thus, the assumed strains have C0 continuity across element boundaries. To the best of the authors' knowledge, CAS elements are the first assumed-strain treatment to effectively overcome membrane locking in quadratic NURBS-based discretizations of Kirchhoff-Love shells while satisfying the following important characteristics for computational efficiency: (1) No additional degrees of freedom are added, (2) No additional systems of algebraic equations need to be solved, (3) No matrix multiplications or matrix inversions are needed to obtain the stiffness matrix, and (4) The nonzero pattern of the stiffness matrix is preserved. The benchmark problems show that CAS elements, using either 2x2 or 3x3 Gauss-Legendre quadrature points per element, are an effective locking treatment since this element type results in more accurate displacements for coarse meshes and excises the spurious oscillations of the membrane forces. The benchmark problems also show that CAS elements outperform state-of-the-art element types based on Lagrange polynomials equipped with either assumed-strain or reduced-integration locking treatments.", "target": "", "edits": [], "_id": 2311.00101}, {"_thresh_template": "# As fine-grained annotation requires complex categories, many successful fine-grained \n# typologies organize their classification in trees. Our interface is unique in that it can \n# render any arbitrary annotation tree, no matter its depth or breath. We will begin with \n# simple annotation setups, and then showcase some complex examples.\n\n# Click the Instructions button to view this :)\n\ninstructions: |\n  ## Adding instructions to your interface\n  Instructions are formatted with [Markdown](https://www.markdownguide.org/cheat-sheet/). \n  You can use the `prepend_instructions` argument to display this text above the interface, or have an \"Instructions\" button.\n\n  ### Formatting\n  Markdown allows creating **bold** or *italicized* text and:\n  - lists\n  - of\n  - items\n\n  ```\n  You can even add blocks of code\n  ```\n  ---\n\n# Comment this to package the instructions using an \"Instructions\" button\n# prepend_instructions: true\n\n# ========================================================================================\n# ========================================================================================\n\n\nedits:\n  # You can specify any number of individual questions\n  - name: multi_question\n    label: \"Annotate Term\"\n    enable_input: true\n    color: blue\n    icon: fa-pen\n    type: single_span\n    annotation:\n      - name: defn_question\n        label: \"Definition\"\n        question: \"Write a one-sentence definition of this term. If you wish to use Google, please use the following search format `define:\\\"<term>\\\"`, substituting your identified term for `<term>` (make sure to include the quotation marks).\"\n        options: textarea\n      - name: difficulty_question\n        label: \"Difficulty\"\n        question: \"How difficult is defining this term?\"\n        options: likert-3\n      - name: category_question\n        label: \"Category\"\n        question: \"Which category would you this term to?\"\n        options: \n          - name: a1\n            label: \"Concept/phrase\"\n          - name: a2\n            label: \"Abbreviation\"\n          - name: a3\n            label: \"Named Entity\"\n          # - name: child_4\n          #   label: \"Other\"\n      - name: multisense_question\n        label: \"Multisense\"\n        question: \"Does this term have different meanings in other domain contexts? If you're uncertain, choose 'Unsure'.\"\n        options: \n          - name: b1\n            label: \"Yes\"\n          - name: b2\n            label: \"No\"\n          - name: b3\n            label: \"Unsure\"\n\n\n\n# ========================================================================================\n# ========================================================================================\n\ntemplate_name: llm_dfs\ntemplate_label: Scientific Concept Identification & Definition\ntemplate_description: TODO\n\n\ndisplay:\n - side-by-side         # shows text and editor next to each other\n#  - text-side-by-side    # shows source and target next to each other\n#  - disable-lines        # disables lines between annotations which can be distracting\n#  - hide-context         # hides the context by default, adding a \"show context\" button\n\ndisable:\n- download        # Disables data download, useful for crowdsourcing\n# - upload          # Disables data upload, useful if data is provided with ?d= parameter\n# - selection     # Disables edit selection\n# - annotation      # Disables edit annotation"}]